{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2694c0be-80bd-4736-823b-5b2628568b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d677df37-c81a-4ae6-958f-14035e8ea322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk                                # Python library for NLP\n",
    "from nltk.corpus import twitter_samples    # sample Twitter dataset from NLTK\n",
    "import matplotlib.pyplot as plt            # library for visualization\n",
    "import random                              # pseudo-random number generator\n",
    "\n",
    "import re                                  # library for regular expression operations\n",
    "import string                              # for string operations\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer        # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8db38519-a7b0-4d76-a59b-24b00b9efd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    g = 1 / (1 + math.e**-z)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d8e2864c-e058-4964-ac87-1f0e203d7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(true_labels, predictions):\n",
    "    #plot confusion matrix\n",
    "    mat = confusion_matrix(true_labels, predictions)\n",
    "    plot_confusion_matrix(conf_mat=mat)\n",
    "\n",
    "    #Calculate precision, recall, f1_score\n",
    "\n",
    "    #precision\n",
    "    precision = precision_score(true_labels, predictions)\n",
    "\n",
    "    #recall\n",
    "    recall = recall_score(true_labels, predictions)\n",
    "\n",
    "    #fl score\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "\n",
    "    #Print precision, recall, f1_score\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6d4d0ea9-3812-4c85-93ea-d1e11eff0382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(labels, predictions):\n",
    "    \n",
    "    # Calculate the number of correct predictions by comparing 'labels' and 'predictions'\n",
    "    correct_predictions = np.sum(labels == predictions)\n",
    "    \n",
    "    # Calculate the total number of predictions\n",
    "    total_predictions = len(labels)\n",
    "    \n",
    "    # Calculate the accuracy as a percentage\n",
    "    accuracy_percentage = (correct_predictions / total_predictions) * 100.0\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0b0850f8-495d-462a-b1c4-89ccb69ba6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(feature_data):\n",
    "    #run feature data through the trained model to get the linera activations from the output layer\n",
    "    logits = model(feature_data)\n",
    "\n",
    "    #convert the model outputs to probabilities by running through the sigmoid function\n",
    "    logits = sigmoid(logits)\n",
    "\n",
    "    # get predictions by converting output probabilities to True if >= 0.5, and False if < 0.5\n",
    "    predictions = logits >= 0.5\n",
    "\n",
    "    #convert True to 1 and False to 0\n",
    "    predictions = [int(boolean) for boolean in predictions]\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1560b62-342d-44d9-9a40-d988cf1c406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##clean tweets\n",
    "def clean_tweets(tweet_lista):\n",
    "    cleaned_list = []\n",
    "    \n",
    "    for tweet in tweet_lista:\n",
    "        # remove old style retweet text \"RT\"\n",
    "        tweet2 = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "        \n",
    "        # remove hyperlinks\n",
    "        tweet2 = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet2)\n",
    "        \n",
    "        # remove hashtags\n",
    "        # only removing the hash # sign from the word\n",
    "        tweet2 = re.sub(r'#', '', tweet2)\n",
    "\n",
    "        cleaned_list.append(tweet2)\n",
    "\n",
    "    return cleaned_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb231e2c-6ba8-4c41-bd62-341c3dba9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweets(tweet_list1):\n",
    "    tokenized_tweets = []\n",
    "    # instantiate tokenizer class\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "\n",
    "    for tweet in tweet_list1:\n",
    "        # tokenize tweets\n",
    "        tweet_tokens = tokenizer.tokenize(tweet)\n",
    "        tokenized_tweets.append(tweet_tokens)\n",
    "\n",
    "    return tokenized_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5f04ccc-4b79-486a-8c7b-cf28d3a2e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tweet_list2):\n",
    "    \n",
    "    cleaned_tweet_list = []\n",
    "    \n",
    "    for tweet_tokens in tweet_list2:\n",
    "        cleaned_tweet = []\n",
    "        #print(tweet_tokens)\n",
    "        for word in tweet_tokens: # Go through every word in your tokens list\n",
    "            if (word not in stopwords_english and word not in string.punctuation):  # remove punctuation # remove stopwords\n",
    "                cleaned_tweet.append(word)\n",
    "        #print(cleaned_tweet)\n",
    "        cleaned_tweet_list.append(cleaned_tweet)\n",
    "\n",
    "    return cleaned_tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8aaf259-fbe8-42cc-8212-b27380659047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tweets(tweet_list):\n",
    "    #Lemmatize\n",
    "    lemmatized_tweets = []\n",
    "    nltk.download('wordnet')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    for tweet in tweet_list:\n",
    "        lemmatized = [lemmatizer.lemmatize(token) for token in tweet]\n",
    "        lemmatized_tweets.append(lemmatized)\n",
    "\n",
    "    return lemmatized_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "402adcbe-90a0-4d9c-b7ec-28d09845eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tweets(tweet_list):\n",
    "    #Instantiate the Stemming Class\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tweets = []\n",
    "    \n",
    "    for tweet in tweet_list:\n",
    "        #create an empty list\n",
    "        tweets_stem = []\n",
    "        for word in tweet:\n",
    "            stem_word = stemmer.stem(word)\n",
    "            tweets_stem.append(stem_word)\n",
    "        \n",
    "        stemmed_tweets.append(tweets_stem) \n",
    "    return stemmed_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e2d2a13-38a0-4ba0-b5a6-7bf61157367e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/krcd58/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloads sample twitter dataset. uncomment the line below if running on a local machine.\n",
    "nltk.download('twitter_samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e79c06e-570e-4a77-9334-85aa3bab99e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c79ce008-1ac5-4d96-ab3c-3b1baf980894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive tweets:  5000\n",
      "Number of negative tweets:  5000\n",
      "\n",
      "The type of all_positive_tweets is:  <class 'list'>\n",
      "The type of a tweet entry is:  <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print('Number of positive tweets: ', len(all_positive_tweets))\n",
    "print('Number of negative tweets: ', len(all_negative_tweets))\n",
    "\n",
    "print('\\nThe type of all_positive_tweets is: ', type(all_positive_tweets))\n",
    "print('The type of a tweet entry is: ', type(all_negative_tweets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c231375-0693-47b5-ab4f-da81bb5b3283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the english stop words list from NLTK\n",
    "stopwords_english = stopwords.words('english') \n",
    "\n",
    "print('Stop words\\n--------------------\\n')\n",
    "print(stopwords_english)\n",
    "\n",
    "print('\\nPunctuation\\n----------------------\\n')\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea02237d-073f-449e-9b0f-04788144e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "#Create labels array\n",
    "positive_labels = np.ones(5000)\n",
    "negative_labels = np.zeros(5000)\n",
    "\n",
    "tweet_labels = np.concatenate((positive_labels, negative_labels))\n",
    "print(tweet_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f76a7b45-124d-4349-b954-7c507f4a66ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Combine positive and negative tweet datasets add a label column\n",
    "all_tweets = all_positive_tweets + all_negative_tweets\n",
    "all_tweets = np.array(all_tweets)\n",
    "print(type(all_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcf9608b-4376-42ce-a421-c0c4aadd8125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Average Review length is 68.5377\n",
      "The Standard Deviation is 37\n"
     ]
    }
   ],
   "source": [
    "length = [len(i) for i in all_tweets]\n",
    "print(\"The Average Review length is\", np.mean(length))\n",
    "print(\"The Standard Deviation is\", round(np.std(length)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3040_kernel",
   "language": "python",
   "name": "3040_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
